{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POLYP SEGMENTATION\n",
    "\n",
    "## The task\n",
    "Given an endoscopic image, we have to predict a binary mask where 1's pixels are the polyps' regions.\n",
    "\n",
    "## Assumptions\n",
    "Let the mask be a random variable $M$ and the input image is also a random variable $X$. To perform the segmentation task, we estimate the conditional probablity $P(M=m|X=x)$. Due to the assumption that the mask is binary, $P(M=m|X=x)$ is a Bernoulli distribution, which means that $P(M=m|X=x) = \\text{Ber}(m|\\lambda(x))$ where $\\lambda(x)$ is modeled using a neural network $G_\\theta(x)$ ($\\theta$ is a set of network's parameters). In conclusion, we have to estimate $\\text{Ber}(m|G_\\theta(x))$. Another assumption is that the elements in an arbitrary $m^{<i>}$ are independent for the sake of calculating the later join probabilities.\n",
    "\n",
    "## Methodology\n",
    "Given a set of training data including endoscopic images $(x^{<1>}, x^{<2>}, ..., x^{<N>})$ and target masks $(m^{<1>}, m^{<2>}, ..., m^{<N>})$ (any $x^{<i>}$ or $m^{<i>}$ is vector-valued), our goal is maximizing the conditional log-likelihood of this training dataset:<br>\n",
    "<center>\n",
    "    <div style=\"display: inline-block; text-align: left;\">\n",
    "        $\\theta^* = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\log P(m^{<i>}|x^{<i>})$<br>\n",
    "        $\\ \\ \\ \\  = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\log \\text{Ber}(m^{<i>}|G_\\theta(x^{<i>}))$<br>\n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "We have assumed that the elements in an arbitrary $m^{<i>}$ are independent. Therefore:<br>\n",
    "<center>\n",
    "    <div style=\"display: inline-block; text-align: left;\">\n",
    "        $\\theta^* = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\sum_{k=1}^K \\log \\text{Ber}(m^{<i>}_k|G_\\theta(x^{<i>})_k)$ <br>\n",
    "        $\\ \\ \\ \\ = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\sum_{k=1}^K \\log G_\\theta(x^{<i>})_k^{m^{<i>}_k} (1 - G_\\theta(x^{<i>})_k)^{1 - m^{<i>}_k}$<br>\n",
    "        $\\ \\ \\ \\ = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\sum_{k=1}^K {m^{<i>}_k}\\log G_\\theta(x^{<i>})_k - ({1 - m^{<i>}_k})\\log(1 - G_\\theta(x^{<i>})_k)$<br>\n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "It turns out that we have to optimize a binary cross-entropy loss function.<br>\n",
    "In the code below, the neural network $G_\\theta(x)$ is modeled as a U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:44.716575Z",
     "iopub.status.busy": "2023-06-24T14:08:44.716155Z",
     "iopub.status.idle": "2023-06-24T14:08:46.342666Z",
     "shell.execute_reply": "2023-06-24T14:08:46.341745Z",
     "shell.execute_reply.started": "2023-06-24T14:08:44.716543Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.348867Z",
     "iopub.status.busy": "2023-06-24T14:08:46.348521Z",
     "iopub.status.idle": "2023-06-24T14:08:46.376380Z",
     "shell.execute_reply": "2023-06-24T14:08:46.374872Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.348834Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.378644Z",
     "iopub.status.busy": "2023-06-24T14:08:46.377861Z",
     "iopub.status.idle": "2023-06-24T14:08:46.390436Z",
     "shell.execute_reply": "2023-06-24T14:08:46.389452Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.378608Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_images(imgs, n_rows=8):    \n",
    "    imgs = tv.utils.make_grid(imgs, n_rows, padding=4)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(imgs.permute(1, 2, 0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.394492Z",
     "iopub.status.busy": "2023-06-24T14:08:46.394072Z",
     "iopub.status.idle": "2023-06-24T14:08:46.404961Z",
     "shell.execute_reply": "2023-06-24T14:08:46.404113Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.394466Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImagePairDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, img_size):\n",
    "        super().__init__()\n",
    "        self.img_paths = [\n",
    "            os.path.join(img_dir, path)\n",
    "            for path in os.listdir(img_dir)\n",
    "            if path.endswith('.jpg')\n",
    "            or path.endswith('.jpeg')\n",
    "            or path.endswith('.png')\n",
    "        ]\n",
    "        self.label_paths = [\n",
    "            os.path.join(label_dir, path)\n",
    "            for path in os.listdir(label_dir)\n",
    "            if path.endswith('.jpg')\n",
    "            or path.endswith('.jpeg')\n",
    "            or path.endswith('.png')\n",
    "        ]\n",
    "        assert len(self.img_paths) == len(self.label_paths)\n",
    "        self.resize = transforms.Resize(img_size, antialias=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = tv.io.read_image(self.img_paths[index])\n",
    "        img = self.resize(img) / 255.0\n",
    "        label = tv.io.read_image(self.label_paths[index])\n",
    "        label = self.resize(label)[0] / 255.0\n",
    "        return img, label.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.407185Z",
     "iopub.status.busy": "2023-06-24T14:08:46.406463Z",
     "iopub.status.idle": "2023-06-24T14:08:46.416234Z",
     "shell.execute_reply": "2023-06-24T14:08:46.415353Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.407152Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.419131Z",
     "iopub.status.busy": "2023-06-24T14:08:46.418873Z",
     "iopub.status.idle": "2023-06-24T14:08:46.429302Z",
     "shell.execute_reply": "2023-06-24T14:08:46.428440Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.419109Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels,\n",
    "                                         kernel_size, stride, padding)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.deconv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.432434Z",
     "iopub.status.busy": "2023-06-24T14:08:46.432071Z",
     "iopub.status.idle": "2023-06-24T14:08:46.441051Z",
     "shell.execute_reply": "2023-06-24T14:08:46.439869Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.432403Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dropout=None):\n",
    "        super().__init__()\n",
    "        self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding='same')\n",
    "        self.conv_block_1 = ConvBlock(in_channels, out_channels, kernel_size, padding='same')\n",
    "        self.conv_2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding='same')\n",
    "        self.norm_2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip = self.res_conv(x)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_2(x) + skip\n",
    "        x = self.norm_2(x)\n",
    "        x = self.relu(x)\n",
    "        if hasattr(self, 'dropout'):\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.442694Z",
     "iopub.status.busy": "2023-06-24T14:08:46.442282Z",
     "iopub.status.idle": "2023-06-24T14:08:46.451087Z",
     "shell.execute_reply": "2023-06-24T14:08:46.450223Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.442664Z"
    }
   },
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dropout=None):\n",
    "        super().__init__()\n",
    "        self.res_block = ResidualBlock(in_channels, out_channels, kernel_size, dropout)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(x)\n",
    "        x = self.res_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.453059Z",
     "iopub.status.busy": "2023-06-24T14:08:46.452488Z",
     "iopub.status.idle": "2023-06-24T14:08:46.464768Z",
     "shell.execute_reply": "2023-06-24T14:08:46.463731Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.453026Z"
    }
   },
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dropout=None):\n",
    "        super().__init__()\n",
    "        self.res_block = ResidualBlock(in_channels, out_channels, kernel_size, dropout)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        x = self.res_block(x)\n",
    "        x = self.upsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.466657Z",
     "iopub.status.busy": "2023-06-24T14:08:46.466408Z",
     "iopub.status.idle": "2023-06-24T14:08:46.481119Z",
     "shell.execute_reply": "2023-06-24T14:08:46.479791Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.466635Z"
    }
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.ModuleList([\n",
    "            ResidualBlock(3, 64, 3, 0.1),\n",
    "            DownBlock(64, 128, 3, 0.1),\n",
    "            DownBlock(128, 256, 3, 0.1),\n",
    "            DownBlock(256, 512, 3, 0.1),\n",
    "            DownBlock(512, 1024, 3, 0.1),\n",
    "        ])\n",
    "        \n",
    "        self.upsample = nn.ModuleList([\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            UpBlock(1024 + 512, 512, 3, 0.1),\n",
    "            UpBlock(512 + 256, 256, 3, 0.1),\n",
    "            UpBlock(256 + 128, 128, 3, 0.1),\n",
    "        ])\n",
    "        \n",
    "        self.last_blocks = nn.ModuleList([\n",
    "            ResidualBlock(128 + 64, 64, 3, 0.1),\n",
    "            nn.Conv2d(64, 1, 3, padding='same'),\n",
    "            nn.Sigmoid(),\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        for block in self.downsample:\n",
    "            x = block(x)\n",
    "            skips.append(x)\n",
    "        skips = reversed(skips[:-1])\n",
    "        for block, skip in zip(self.upsample, skips):\n",
    "            x = block(x)\n",
    "            x = torch.concat([x, skip], dim=1)\n",
    "        for block in self.last_blocks:\n",
    "            x = block(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:46:19.860595Z",
     "iopub.status.busy": "2023-06-24T14:46:19.859229Z",
     "iopub.status.idle": "2023-06-24T14:46:19.871814Z",
     "shell.execute_reply": "2023-06-24T14:46:19.870382Z",
     "shell.execute_reply.started": "2023-06-24T14:46:19.860562Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(val_data_loader):\n",
    "    net.eval()\n",
    "    N = len(val_data_loader)\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    for images, labels in val_data_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = net(images)\n",
    "        loss += F.binary_cross_entropy(pred, labels)\n",
    "        acc += (pred.round() == labels).sum() / labels.numel()\n",
    "    loss /= N\n",
    "    acc /= N\n",
    "    return loss.item(), acc.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_batch(images, labels):\n",
    "    net.eval()\n",
    "    pred = net(images)\n",
    "    loss = F.binary_cross_entropy(pred, labels)\n",
    "    acc = (pred.round() == labels).sum() / labels.numel()\n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:53:37.786944Z",
     "iopub.status.busy": "2023-06-24T14:53:37.786558Z",
     "iopub.status.idle": "2023-06-24T14:53:37.793934Z",
     "shell.execute_reply": "2023-06-24T14:53:37.792954Z",
     "shell.execute_reply.started": "2023-06-24T14:53:37.786914Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(images, labels):\n",
    "    net.eval()\n",
    "    loss, acc = evaluate_batch(images, labels)\n",
    "    print(f'loss: {loss:.8f} - acc: {acc:.8f}')\n",
    "    mask_pred = net(images)\n",
    "    plot_images(images.cpu())\n",
    "    plot_images(0.5 * (images + mask_pred.unsqueeze(1)).cpu())\n",
    "    print('Predicted masks:')\n",
    "    plot_images(mask_pred.unsqueeze(1).cpu())\n",
    "    print('Ground truth:')\n",
    "    plot_images(labels.unsqueeze(1).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:08:46.492808Z",
     "iopub.status.busy": "2023-06-24T14:08:46.492282Z",
     "iopub.status.idle": "2023-06-24T14:08:48.424999Z",
     "shell.execute_reply": "2023-06-24T14:08:48.424046Z",
     "shell.execute_reply.started": "2023-06-24T14:08:46.492777Z"
    }
   },
   "outputs": [],
   "source": [
    "net = UNet()\n",
    "net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:33:55.160106Z",
     "iopub.status.busy": "2023-06-24T14:33:55.159755Z",
     "iopub.status.idle": "2023-06-24T14:33:55.174715Z",
     "shell.execute_reply": "2023-06-24T14:33:55.173803Z",
     "shell.execute_reply.started": "2023-06-24T14:33:55.160079Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = ImagePairDataset(\n",
    "    img_dir='/kaggle/input/sun-data/Kvasir_SEG_Training_880/Kvasir_SEG_Training_880/image',\n",
    "    label_dir='/kaggle/input/sun-data/Kvasir_SEG_Training_880/Kvasir_SEG_Training_880/mask',\n",
    "    img_size=(64, 64)\n",
    ")\n",
    "val_ds = ImagePairDataset(\n",
    "    img_dir='/kaggle/input/sun-data/Kvasir_SEG_Validation_120/Kvasir_SEG_Validation_120/images',\n",
    "    label_dir='/kaggle/input/sun-data/Kvasir_SEG_Validation_120/Kvasir_SEG_Validation_120/masks',\n",
    "    img_size=(64, 64)\n",
    ")\n",
    "\n",
    "train_data_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_data_loader = DataLoader(val_ds, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-24T14:59:15.803362Z",
     "iopub.status.busy": "2023-06-24T14:59:15.801825Z",
     "iopub.status.idle": "2023-06-24T15:03:04.740348Z",
     "shell.execute_reply": "2023-06-24T15:03:04.739380Z",
     "shell.execute_reply.started": "2023-06-24T14:59:15.803295Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "for epoch in range(1, 1 + EPOCHS):\n",
    "    for images, labels in (bar := tqdm(train_data_loader)):\n",
    "        net.train()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = net(images)\n",
    "        loss = F.binary_cross_entropy(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            train_acc = (pred.detach().round() == labels).sum()\n",
    "            train_acc = train_acc.float() / labels.numel()\n",
    "            history['train_acc'].append(train_acc.item())\n",
    "            train_loss = loss.detach().item()\n",
    "            history['train_loss'].append(train_loss)\n",
    "        \n",
    "        val_loss, val_acc = evaluate(val_data_loader)\n",
    "        bar.set_description(\n",
    "            ' - '.join([\n",
    "                f'epoch: {epoch}/{EPOCHS}',\n",
    "                f'train_loss: {train_loss:.8f}',\n",
    "                f'train_acc: {train_acc:.8f}',\n",
    "                f'val_loss: {val_loss:.8f}',\n",
    "                f'val_acc: {val_acc:.8f}',\n",
    "            ])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'unet.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
