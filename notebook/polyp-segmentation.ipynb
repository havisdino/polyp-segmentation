{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# POLYP SEGMENTATION\n\n## The task\nGiven an endoscopic image, we have to predict a binary mask where 1's pixels are the polyps' regions.\n\n## Assumptions\nLet the mask be a random variable $M$ and the input image is also a random variable $X$. To perform the segmentation task, we estimate the conditional probablity $P(M=m|X=x)$. Due to the assumption that the mask is binary, $P(M=m|X=x)$ is a Bernoulli distribution, which means that $m|x \\sim \\text{Ber}(\\lambda(x))$ where $\\lambda(x)$ is modeled using a neural network $G_\\theta(x)$ ($\\theta$ is a set of the network's parameters). In conclusion, we have to estimate $\\text{Ber}(m|G_\\theta(x))$. Another assumption is that the elements in an arbitrary $m^{<i>}$ are independent for the sake of calculating the later join probabilities.\n\n## Methodology\nGiven a set of training data including endoscopic images $(x^{<1>}, x^{<2>}, ..., x^{<N>})$ and target masks $(m^{<1>}, m^{<2>}, ..., m^{<N>})$ (any $x^{<i>}$ or $m^{<i>}$ is vector-valued), our goal is maximizing the conditional log-likelihood of this training dataset:<br>\n<center>\n    <div style=\"display: inline-block; text-align: left;\">\n        $\\theta^* = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\log P(m^{<i>}|x^{<i>})$<br>\n        $\\ \\ \\ \\  = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\log \\text{Ber}(m^{<i>};G_\\theta(x^{<i>}))$<br>\n    </div>\n</center>\n\nWe have assumed that the elements in an arbitrary $m^{<i>}$ are independent. Therefore:<br>\n<center>\n    <div style=\"display: inline-block; text-align: left;\">\n        $\\theta^* = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\sum_{k=1}^K \\log \\text{Ber}(m^{<i>}_k;G_\\theta(x^{<i>})_k)$ <br>\n        $\\ \\ \\ \\ = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\sum_{k=1}^K \\log G_\\theta(x^{<i>})_k^{m^{<i>}_k} (1 - G_\\theta(x^{<i>})_k)^{1 - m^{<i>}_k}$<br>\n        $\\ \\ \\ \\ = \\text{argmax}_\\theta\\ \\sum_{i=1}^N \\sum_{k=1}^K {m^{<i>}_k}\\log G_\\theta(x^{<i>})_k - ({1 - m^{<i>}_k})\\log(1 - G_\\theta(x^{<i>})_k)$<br>\n    </div>\n</center>\n\nIt turns out that we have to optimize a binary cross-entropy loss function.<br>\nIn the code below, the neural network $G_\\theta(x)$ is modeled as a U-Net.","metadata":{"execution":{"iopub.status.busy":"2023-06-25T16:17:05.624266Z","iopub.execute_input":"2023-06-25T16:17:05.624874Z","iopub.status.idle":"2023-06-25T16:17:05.650114Z","shell.execute_reply.started":"2023-06-25T16:17:05.624839Z","shell.execute_reply":"2023-06-25T16:17:05.648658Z"}}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision as tv\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nimport os","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(imgs, n_rows=8):    \n    imgs = tv.utils.make_grid(imgs, n_rows, padding=4)\n    plt.figure(figsize=(12, 12))\n    plt.imshow(imgs.permute(1, 2, 0))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImagePairDataset(Dataset):\n    def __init__(self, img_dir, label_dir, img_size):\n        super().__init__()\n        self.img_paths = [\n            os.path.join(img_dir, path)\n            for path in os.listdir(img_dir)\n            if path.endswith('.jpg')\n            or path.endswith('.jpeg')\n            or path.endswith('.png')\n        ]\n        self.label_paths = [\n            os.path.join(label_dir, path)\n            for path in os.listdir(label_dir)\n            if path.endswith('.jpg')\n            or path.endswith('.jpeg')\n            or path.endswith('.png')\n        ]\n        assert len(self.img_paths) == len(self.label_paths)\n        self.resize = transforms.Resize(img_size, antialias=True)\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, index):\n        img = tv.io.read_image(self.img_paths[index])\n        img = self.resize(img) / 255.0\n        label = tv.io.read_image(self.label_paths[index])\n        label = self.resize(label)[0] / 255.0\n        return img, label.round()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels,\n                              kernel_size, stride, padding)\n        self.norm = nn.BatchNorm2d(out_channels)\n        self.relu = nn.LeakyReLU(0.2)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.norm(x)\n        x = self.relu(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DeconvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super().__init__()\n        self.deconv = nn.ConvTranspose2d(in_channels, out_channels,\n                                         kernel_size, stride, padding)\n        self.norm = nn.BatchNorm2d(out_channels)\n        self.relu = nn.LeakyReLU(0.2)\n\n    def forward(self, x):\n        x = self.deconv(x)\n        x = self.norm(x)\n        x = self.relu(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dropout=None):\n        super().__init__()\n        self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding='same')\n        self.conv_block_1 = ConvBlock(in_channels, out_channels, kernel_size, padding='same')\n        self.conv_2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding='same')\n        self.norm_2 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.LeakyReLU(0.2)\n        if dropout:\n            self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        skip = self.res_conv(x)\n        x = self.conv_block_1(x)\n        x = self.conv_2(x) + skip\n        x = self.norm_2(x)\n        x = self.relu(x)\n        if hasattr(self, 'dropout'):\n            x = self.dropout(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DownBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dropout=None):\n        super().__init__()\n        self.res_block = ResidualBlock(in_channels, out_channels, kernel_size, dropout)\n        self.maxpool = nn.MaxPool2d(2)\n    \n    def forward(self, x):\n        x = self.maxpool(x)\n        x = self.res_block(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UpBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dropout=None):\n        super().__init__()\n        self.res_block = ResidualBlock(in_channels, out_channels, kernel_size, dropout)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n    \n    def forward(self, x):        \n        x = self.res_block(x)\n        x = self.upsample(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.downsample = nn.ModuleList([\n            ResidualBlock(3, 64, 3, 0.1),\n            DownBlock(64, 128, 3, 0.1),\n            DownBlock(128, 256, 3, 0.1),\n            DownBlock(256, 512, 3, 0.1),\n            DownBlock(512, 1024, 3, 0.1),\n        ])\n        \n        self.upsample = nn.ModuleList([\n            nn.Upsample(scale_factor=2, mode='bilinear'),\n            UpBlock(1024 + 512, 512, 3, 0.1),\n            UpBlock(512 + 256, 256, 3, 0.1),\n            UpBlock(256 + 128, 128, 3, 0.1),\n        ])\n        \n        self.last_blocks = nn.ModuleList([\n            ResidualBlock(128 + 64, 64, 3, 0.1),\n            nn.Conv2d(64, 1, 3, padding='same'),\n            nn.Sigmoid(),\n        ])\n    \n    def forward(self, x):\n        skips = []\n        for block in self.downsample:\n            x = block(x)\n            skips.append(x)\n        skips = reversed(skips[:-1])\n        for block, skip in zip(self.upsample, skips):\n            x = block(x)\n            x = torch.concat([x, skip], dim=1)\n        for block in self.last_blocks:\n            x = block(x)\n        return x.squeeze()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(val_data_loader):\n    net.eval()\n    N = len(val_data_loader)\n    loss = 0\n    acc = 0\n    for images, labels in val_data_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        pred = net(images)\n        loss += F.binary_cross_entropy(pred, labels)\n        acc += (pred.round() == labels).sum() / labels.numel()\n    loss /= N\n    acc /= N\n    return loss.item(), acc.item()\n\n\n@torch.no_grad()\ndef evaluate_batch(images, labels):\n    net.eval()\n    pred = net(images)\n    loss = F.binary_cross_entropy(pred, labels)\n    acc = (pred.round() == labels).sum() / labels.numel()\n    return loss.item(), acc.item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef test(images, labels):\n    net.eval()\n    loss, acc = evaluate_batch(images, labels)\n    print(f'loss: {loss:.8f} - acc: {acc:.8f}')\n    mask_pred = net(images)\n    plot_images(images.cpu())\n    plot_images((images * 0.4 + 0.6 * mask_pred.unsqueeze(1)).cpu())\n    print('Predicted masks:')\n    plot_images(mask_pred.unsqueeze(1).cpu())\n    print('Ground truth:')\n    plot_images(labels.unsqueeze(1).cpu())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = UNet()\nnet = nn.DataParallel(net)\nnet.to(device)\noptimizer = torch.optim.Adam(net.parameters())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = ImagePairDataset(\n    img_dir='/kaggle/input/intern-data/Kvasir_SEG_Training_880/Kvasir_SEG_Training_880/image',\n    label_dir='/kaggle/input/intern-data/Kvasir_SEG_Training_880/Kvasir_SEG_Training_880/mask',\n    img_size=(128, 128)\n)\nval_ds = ImagePairDataset(\n    img_dir='/kaggle/input/intern-data/Kvasir_SEG_Validation_120/Kvasir_SEG_Validation_120/images',\n    label_dir='/kaggle/input/intern-data/Kvasir_SEG_Validation_120/Kvasir_SEG_Validation_120/masks',\n    img_size=(128, 128)\n)\n\ntrain_data_loader = DataLoader(train_ds, batch_size=128, shuffle=True, prefetch_factor=2, num_workers=2)\nval_data_loader = DataLoader(val_ds, batch_size=32, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 30\nhistory = {\n    'train_loss': [],\n    'train_acc': [],\n    'val_loss': [],\n    'val_acc': []\n}\nbest_weight_state = None\n\nfor epoch in range(1, 1 + EPOCHS):\n    for images, labels in (bar := tqdm(train_data_loader)):\n        net.train()\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        pred = net(images)\n        loss = F.binary_cross_entropy(pred, labels)\n        loss.backward()\n        optimizer.step()\n        \n        with torch.no_grad():\n            train_acc = (pred.detach().round() == labels).sum()\n            train_acc = train_acc.float() / labels.numel()\n            history['train_acc'].append(train_acc.item())\n            train_loss = loss.detach().item()\n            history['train_loss'].append(train_loss)\n        \n        val_loss, val_acc = evaluate(val_data_loader)\n        if all(val_acc > acc for acc in history['val_acc']):\n            best_weight_state = (net.state_dict(),\n                                 {'train_acc': train_acc.item(),\n                                  'val_acc': val_acc,\n                                  'epoch': epoch})\n        \n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        bar.set_description(\n            ' - '.join([\n                f'epoch: {epoch}/{EPOCHS}',\n                f'train_loss: {train_loss:.8f}',\n                f'train_acc: {train_acc:.8f}',\n                f'val_loss: {val_loss:.8f}',\n                f'val_acc: {val_acc:.8f}',\n            ])\n        )\nprint(f'The best weight state: \\n{best_weight_state[1]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_iter = iter(val_data_loader)\nnet.load_state_dict(best_weight_state[0])\n\nimages, labels = next(val_iter)\nimages = images.to(device)\nlabels = labels.to(device)\ntest(images[:16], labels[:16])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(best_weight_state[0], 'best_weights.pt')\ntorch.save(net.module.state_dict(), 'unet_128.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}